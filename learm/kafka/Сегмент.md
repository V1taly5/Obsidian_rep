Сегмент тоже удобно представить как обычный лог-файл: каждая следующая запись добавляется в конец файла и не меняет предыдущих записей. Фактически это очередь FIFO (First-In-First-Out) и Kafka реализует именно эту модель.
![[Pasted image 20240309120458.png]]

Семантически и физически события внутри сегмента не могут быть удалены, они иммутабельны. Все, что мы можем - указать, как долго Kafka-брокер будет хранить события через настройку политики устаревания данных или **_Retention Policy_**
Числа внутри сегмента - это реальные сообщения системы, у которых есть порядковые номера или оффсеты, что монотонно увеличиваются со временем. У каждой партиции свой собственный счетчик, и он никак не пересекается с другими партициями - позиции 0, 1, 2, 3 и так далее к каждой партиции свои. Таким образом, продюсеры пишут сообщения в партиции, а брокер адресует каждое из таких сообщений своим порядковым номерам.

Помимо продюсеров, что пишут сообщения, есть консумеры, которые их читают. У лога может быть несколько консумеров, которые читают его с разных позиций, и не мешают друг другу. А ещё у консумеров нет жёсткой привязки к чтению событий по времени. При желании они могут читать спустя дни, недели, месяцы, или вовсе несколько раз спустя какое-то время.
![[Pasted image 20240309121559.png]]
Начальная позиция первого сообщения в логе называется **_log-start offset_**. Позиция сообщения, записанного последним — **_log-end offset_**. Позиция консумера сейчас — **_current offset_**.
![[Pasted image 20240309121742.png]]
Расстояние между конечным оффсетом и текущим оффсетом консумера называют **_лагом_** — это первое, за чем стоит следить в своих приложениях. Допустимый лаг для каждого приложения свой, это тесно связано с бизнес-логикой и требованиями к работе системы.
[[Сообщения Kafka]]