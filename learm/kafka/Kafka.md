кафка за 20 минут https://habr.com/ru/companies/sbermarket/articles/738634/
Основы кластера Kafka - это **[[продюсер]]**, **[[брокер]]** и **[[консумер]]**. **[[Продюсер]]** пишет события в [[лог]] брокера, а **[[консумер]]** читает из него.

**Apache Kafka** управляет логами и организует платформу, которая соединяет поставщиков данных с потребителями и дает возможность получать упорядоченный поток событий в реальном времени.

 Kafka — это нечто, что обслуживается инфраструктурой, где мы как пользователи пишим продюсеров и консумеров. Программа-консумер подписывается на события или **_пуллит_** и получает данные в ответ. Так продолжается по кругу.
 ![[Pasted image 20240307192720.png]]
## Kafka архитектура
Слева есть продюсеры, в середине брокеры, справа консумеры. Инструмент представляет собой группу брокеров, связанных с [[Zookeeper]]-кворумом. Kafka использует Zookeper для достижения консенсуса состояния в распределенной системе: есть несколько вещей, с которыми должен быть "согласен" каждый брокер и Zookerper помогает достичь этого "согласия" внутри кластера. 
![[Pasted image 20240307210201.png]]

Топики в Kafka разделены на **_партиции_**. Увеличение партиции увеличивает парвллелизм чтения и записи. Партиции находятся на одной или нескольких брокерах, что позволяет кластеру масштабироваться. 
Партиции хранятся на локальных дисках брокеров и представлены набором лог-файлов -  сегментов. Запись в них идет в конец, а уже сохраненные события неизменны.
Каждое сообщение в таком логе определяется порядковым номером - оффсетом. 
Этот номер монотонно увеличивается при записи для каждой партиции.
Лог-файлы на диске устаревают по времени и размеру. Настроить это можно глобально или индивидуально в каждом топике.
Для отказоустойчивости, партиции могут реплицироваться. Число реплик или фактор репликации настраивается как глобально по умолчанию, так и отдельно в каждом топике.
Реплики партиций могут быть лидерами или фолловерами. Традиционно клнсумеры и продюсеры работают с лидерами, а фоловеры только догоняют лидера.  

## Устройство брокеров
Перейдем к брокерам и рассмотрим их детальнее. Начать стоит с [[Топики|топиков]].

## [[Топики|Топики]]

## [[Партиции и сегметы]]

## [[Сегмент|Поток данных как лог]]

## [[Устаревание данных]]

## [[Репликация данных]]

## Устройство продюсеров 
После брокеров логично перейти к продюсерам и понять принцип их работы. Продюсеры пишут сообщения в партиции, партиции расположены на брокерах. Возникает вопрос — как продюсер узнаёт о том, какое сообщение и в какую партицию ему записать?
После брокеров логично перейти к продюсерам и понять принцип их работы. Продюсеры пишут сообщения в партиции, партиции расположены на брокерах. Возникает вопрос — как продюсер узнаёт о том, какое сообщение и в какую партицию ему записать?
## [[Балансировка и партицирование]]
## [[Дизайн продюсера]]
## [[Семантики доставки]]
## [[Надежность доставки]]
## [[Идемпотентные продюсеры]]

## [[Дизайн консумера]]
## [[Консумер группы]]

## [[Ребалансировка консумер-групп]]


[A Practical Guide To Using Golang With Apache Kafka (withcodeexample.com)](https://golang.withcodeexample.com/blog/a-practical-guide-to-using-golang-with-apache-kafka/)

Идеи проектов для изучения:

1. **Интеграция Kafka с другими сервисами**:
    - Попробуйте интегрировать Kafka с базой данных (например, PostgreSQL или MongoDB).
    - Отправляйте изменения в базе данных в Kafka и наоборот.
    - Это поможет вам понять, как Kafka может быть использована в реальных приложениях.